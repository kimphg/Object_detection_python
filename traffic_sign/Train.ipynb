{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:06.163853Z",
     "start_time": "2019-04-01T13:53:59.624780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "x = np.load(\"x.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "shuffe_index = np.random.permutation(x.shape[0])\n",
    "N = x.shape[0]\n",
    "K = int(0.8*N)#number of train samples\n",
    "index = np.random.permutation(N)\n",
    "x_train = x[index[0:K]]\n",
    "y_train = y[index[0:K]]\n",
    "x_test = x[index[K:]]\n",
    "y_test = y[index[K:]]\n",
    "print(N, K, N - K)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 55  82  78]\n",
      "   [ 53  80  76]\n",
      "   [ 51  78  74]\n",
      "   ...\n",
      "   [ 33  55  50]\n",
      "   [ 43  65  60]\n",
      "   [ 46  68  63]]\n",
      "\n",
      "  [[ 54  81  77]\n",
      "   [ 53  80  76]\n",
      "   [ 51  78  74]\n",
      "   ...\n",
      "   [ 33  55  50]\n",
      "   [ 42  64  59]\n",
      "   [ 45  67  62]]\n",
      "\n",
      "  [[ 53  80  76]\n",
      "   [ 53  80  76]\n",
      "   [ 51  78  74]\n",
      "   ...\n",
      "   [ 34  56  51]\n",
      "   [ 44  67  62]\n",
      "   [ 46  69  64]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 38 115 101]\n",
      "   [ 39 116 102]\n",
      "   [ 41 117 105]\n",
      "   ...\n",
      "   [ 84 128 121]\n",
      "   [ 94 136 129]\n",
      "   [ 98 139 132]]\n",
      "\n",
      "  [[ 40 114 102]\n",
      "   [ 42 116 104]\n",
      "   [ 47 119 107]\n",
      "   ...\n",
      "   [ 85 127 120]\n",
      "   [ 96 134 128]\n",
      "   [100 136 130]]\n",
      "\n",
      "  [[ 42 114 102]\n",
      "   [ 43 115 103]\n",
      "   [ 50 119 108]\n",
      "   ...\n",
      "   [ 86 127 120]\n",
      "   [ 97 133 127]\n",
      "   [102 136 130]]]\n",
      "\n",
      "\n",
      " [[[ 80  90  97]\n",
      "   [ 77  87  94]\n",
      "   [ 74  83  87]\n",
      "   ...\n",
      "   [ 81 124 121]\n",
      "   [ 85 127 126]\n",
      "   [ 84 128 127]]\n",
      "\n",
      "  [[ 80  90  97]\n",
      "   [ 79  89  96]\n",
      "   [ 77  86  90]\n",
      "   ...\n",
      "   [ 82 122 120]\n",
      "   [ 84 126 125]\n",
      "   [ 83 127 126]]\n",
      "\n",
      "  [[ 81  90  94]\n",
      "   [ 81  90  94]\n",
      "   [ 77  88  92]\n",
      "   ...\n",
      "   [ 81 120 118]\n",
      "   [ 84 124 123]\n",
      "   [ 84 126 125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 97 135 137]\n",
      "   [ 92 130 132]\n",
      "   [ 79 114 117]\n",
      "   ...\n",
      "   [132 166 166]\n",
      "   [134 165 166]\n",
      "   [136 167 166]]\n",
      "\n",
      "  [[116 157 160]\n",
      "   [106 147 149]\n",
      "   [ 87 126 128]\n",
      "   ...\n",
      "   [134 168 168]\n",
      "   [137 168 169]\n",
      "   [140 170 171]]\n",
      "\n",
      "  [[128 171 174]\n",
      "   [113 156 159]\n",
      "   [ 91 130 132]\n",
      "   ...\n",
      "   [134 167 170]\n",
      "   [137 168 169]\n",
      "   [140 170 171]]]\n",
      "\n",
      "\n",
      " [[[ 78  88  82]\n",
      "   [ 76  83  78]\n",
      "   [ 88  94  89]\n",
      "   ...\n",
      "   [ 75 119 118]\n",
      "   [ 83 133 133]\n",
      "   [ 85 137 137]]\n",
      "\n",
      "  [[ 80  87  82]\n",
      "   [ 92  98  93]\n",
      "   [109 113 108]\n",
      "   ...\n",
      "   [ 73 117 116]\n",
      "   [ 79 127 128]\n",
      "   [ 79 131 131]]\n",
      "\n",
      "  [[101 105  99]\n",
      "   [110 112 106]\n",
      "   [127 127 121]\n",
      "   ...\n",
      "   [ 73 117 116]\n",
      "   [ 79 127 128]\n",
      "   [ 81 131 131]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[130 164 170]\n",
      "   [128 162 168]\n",
      "   [130 164 170]\n",
      "   ...\n",
      "   [ 45 124 105]\n",
      "   [ 47 126 107]\n",
      "   [ 64 143 122]]\n",
      "\n",
      "  [[135 162 172]\n",
      "   [134 163 172]\n",
      "   [133 162 171]\n",
      "   ...\n",
      "   [ 39 124 102]\n",
      "   [ 41 126 104]\n",
      "   [ 40 126 102]]\n",
      "\n",
      "  [[134 159 169]\n",
      "   [138 163 173]\n",
      "   [130 157 167]\n",
      "   ...\n",
      "   [ 32 120  97]\n",
      "   [ 37 128 103]\n",
      "   [ 39 130 105]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 25  51  51]\n",
      "   [ 27  53  53]\n",
      "   [ 31  58  55]\n",
      "   ...\n",
      "   [ 45  66  64]\n",
      "   [ 41  63  61]\n",
      "   [ 37  59  57]]\n",
      "\n",
      "  [[ 25  51  51]\n",
      "   [ 29  55  55]\n",
      "   [ 33  60  57]\n",
      "   ...\n",
      "   [ 44  65  62]\n",
      "   [ 42  63  61]\n",
      "   [ 38  61  57]]\n",
      "\n",
      "  [[ 23  50  47]\n",
      "   [ 29  56  53]\n",
      "   [ 35  64  61]\n",
      "   ...\n",
      "   [ 41  63  58]\n",
      "   [ 42  63  60]\n",
      "   [ 41  63  58]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[102 127 123]\n",
      "   [103 128 124]\n",
      "   [102 129 125]\n",
      "   ...\n",
      "   [111 136 132]\n",
      "   [115 136 133]\n",
      "   [115 136 133]]\n",
      "\n",
      "  [[105 130 126]\n",
      "   [106 131 127]\n",
      "   [105 132 129]\n",
      "   ...\n",
      "   [110 135 131]\n",
      "   [114 136 131]\n",
      "   [113 135 130]]\n",
      "\n",
      "  [[106 131 127]\n",
      "   [107 132 128]\n",
      "   [107 134 131]\n",
      "   ...\n",
      "   [110 135 131]\n",
      "   [113 135 130]\n",
      "   [112 134 129]]]\n",
      "\n",
      "\n",
      " [[[ 78 114 108]\n",
      "   [ 78 114 108]\n",
      "   [ 82 113 110]\n",
      "   ...\n",
      "   [134 147 139]\n",
      "   [135 148 140]\n",
      "   [134 147 139]]\n",
      "\n",
      "  [[ 79 115 109]\n",
      "   [ 78 114 108]\n",
      "   [ 81 112 109]\n",
      "   ...\n",
      "   [132 145 137]\n",
      "   [133 146 138]\n",
      "   [133 146 138]]\n",
      "\n",
      "  [[ 78 114 108]\n",
      "   [ 76 112 106]\n",
      "   [ 79 110 107]\n",
      "   ...\n",
      "   [131 143 137]\n",
      "   [135 145 139]\n",
      "   [136 146 140]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 44 117 101]\n",
      "   [ 44 117 101]\n",
      "   [ 46 117 101]\n",
      "   ...\n",
      "   [103 124 126]\n",
      "   [104 123 128]\n",
      "   [102 121 126]]\n",
      "\n",
      "  [[ 47 113 101]\n",
      "   [ 47 113 101]\n",
      "   [ 49 115 103]\n",
      "   ...\n",
      "   [ 76  96  97]\n",
      "   [ 73  90  93]\n",
      "   [ 68  85  88]]\n",
      "\n",
      "  [[ 47 111  99]\n",
      "   [ 49 113 101]\n",
      "   [ 52 116 104]\n",
      "   ...\n",
      "   [ 64  84  85]\n",
      "   [ 57  74  77]\n",
      "   [ 50  67  70]]]\n",
      "\n",
      "\n",
      " [[[ 30  54  52]\n",
      "   [ 29  53  51]\n",
      "   [ 27  54  51]\n",
      "   ...\n",
      "   [ 17  48  45]\n",
      "   [ 18  49  46]\n",
      "   [ 20  51  48]]\n",
      "\n",
      "  [[ 28  52  50]\n",
      "   [ 23  47  45]\n",
      "   [ 19  46  43]\n",
      "   ...\n",
      "   [ 13  44  41]\n",
      "   [ 17  48  45]\n",
      "   [ 20  51  48]]\n",
      "\n",
      "  [[ 32  56  54]\n",
      "   [ 22  46  44]\n",
      "   [ 14  38  36]\n",
      "   ...\n",
      "   [ 12  41  38]\n",
      "   [ 17  46  43]\n",
      "   [ 20  49  46]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99 128 125]\n",
      "   [ 98 127 124]\n",
      "   [104 131 128]\n",
      "   ...\n",
      "   [ 99 131 126]\n",
      "   [ 98 131 124]\n",
      "   [ 97 130 123]]\n",
      "\n",
      "  [[ 98 130 125]\n",
      "   [ 98 128 123]\n",
      "   [102 129 126]\n",
      "   ...\n",
      "   [ 97 129 124]\n",
      "   [ 95 127 122]\n",
      "   [ 92 126 120]]\n",
      "\n",
      "  [[ 96 128 123]\n",
      "   [ 96 128 123]\n",
      "   [ 99 126 123]\n",
      "   ...\n",
      "   [ 94 126 121]\n",
      "   [ 90 124 118]\n",
      "   [ 88 122 116]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:08.270193Z",
     "start_time": "2019-04-01T13:54:08.168465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         608       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 7,442\n",
      "Trainable params: 7,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(5, 5), strides= (2, 2), padding='same',input_shape=( 64, 64, 3,)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 243\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape[0], x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:20.042987Z",
     "start_time": "2019-04-01T13:54:09.103294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "8/7 [===============================] - 0s 48ms/step - loss: 0.4926 - val_loss: 0.3511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35113, saving model to models/sign.h5\n",
      "Epoch 2/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.3268 - val_loss: 0.2611\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35113 to 0.26112, saving model to models/sign.h5\n",
      "Epoch 3/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.2668 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26112 to 0.24335, saving model to models/sign.h5\n",
      "Epoch 4/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.2669 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24335 to 0.16945, saving model to models/sign.h5\n",
      "Epoch 5/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 0.2338 - val_loss: 0.1265\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16945 to 0.12653, saving model to models/sign.h5\n",
      "Epoch 6/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.1509 - val_loss: 0.0832\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12653 to 0.08322, saving model to models/sign.h5\n",
      "Epoch 7/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.1188 - val_loss: 0.0525\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08322 to 0.05248, saving model to models/sign.h5\n",
      "Epoch 8/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 0.0779 - val_loss: 0.0421\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05248 to 0.04208, saving model to models/sign.h5\n",
      "Epoch 9/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0675 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04208 to 0.02256, saving model to models/sign.h5\n",
      "Epoch 10/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0444 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02256\n",
      "Epoch 11/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02256 to 0.01331, saving model to models/sign.h5\n",
      "Epoch 12/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01331\n",
      "Epoch 13/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01331 to 0.01063, saving model to models/sign.h5\n",
      "Epoch 14/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01063\n",
      "Epoch 15/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01063\n",
      "Epoch 16/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01063\n",
      "Epoch 17/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01063\n",
      "Epoch 18/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01063\n",
      "Epoch 19/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01063\n",
      "Epoch 20/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0042 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01063\n",
      "Epoch 21/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01063\n",
      "Epoch 22/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01063 to 0.00612, saving model to models/sign.h5\n",
      "Epoch 23/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00612\n",
      "Epoch 24/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00612\n",
      "Epoch 25/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00612\n",
      "Epoch 26/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00612\n",
      "Epoch 27/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00612\n",
      "Epoch 28/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00612 to 0.00556, saving model to models/sign.h5\n",
      "Epoch 29/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00556\n",
      "Epoch 30/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00556\n",
      "Epoch 31/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00556\n",
      "Epoch 32/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00556\n",
      "Epoch 33/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00556\n",
      "Epoch 34/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 7.0885e-04 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00556\n",
      "Epoch 35/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00556 to 0.00313, saving model to models/sign.h5\n",
      "Epoch 36/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00313 to 0.00272, saving model to models/sign.h5\n",
      "Epoch 37/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00272\n",
      "Epoch 38/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00272\n",
      "Epoch 39/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 9.6808e-04 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00272\n",
      "Epoch 40/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00272\n",
      "Epoch 41/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00272\n",
      "Epoch 42/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00272\n",
      "Epoch 43/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00272\n",
      "Epoch 44/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00272\n",
      "Epoch 45/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 8.4928e-04\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00272 to 0.00085, saving model to models/sign.h5\n",
      "Epoch 46/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00085\n",
      "Epoch 47/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00085\n",
      "Epoch 48/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00085\n",
      "Epoch 49/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 8.8011e-04 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00085\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/7 [===============================] - 0s 12ms/step - loss: 6.5204e-04 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00085\n"
     ]
    }
   ],
   "source": [
    "def generator(x, y, batch_size):\n",
    "    samples = x.shape[0]\n",
    "    steps = samples/batch_size\n",
    "    counter =0\n",
    "    while True:\n",
    "        batch_x = np.array(x[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        batch_x = batch_x/255.0\n",
    "        batch_y = np.array(y[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        counter+=1\n",
    "        yield batch_x, batch_y\n",
    "        if counter >= steps:\n",
    "            counter = 0\n",
    "# batch_size = 128\n",
    "batch_size = 32\n",
    "epochs=50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"models/sign.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history= model.fit_generator(generator(x_train, y_train, batch_size), epochs=epochs, steps_per_epoch = x_train.shape[0]/batch_size, \n",
    "                             validation_data=generator(x_test, y_test, batch_size), validation_steps = x_test.shape[0]/batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:32.252242Z",
     "start_time": "2019-04-01T13:54:31.576388Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import time\n",
    "model = load_model(\"models/sign.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:55:27.425674Z",
     "start_time": "2019-04-01T13:54:33.687435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07115602493286133\n",
      "[0.99999845 1.        ]\n",
      "[0.00312188 0.9999993 ]\n",
      "[0.99979424 0.9999852 ]\n",
      "[0.9999997 1.       ]\n",
      "[0.99998474 0.9999999 ]\n",
      "[1.3104081e-04 1.0000000e+00]\n",
      "[0.99993443 0.9999999 ]\n",
      "[3.8522482e-04 1.0000000e+00]\n",
      "[0.0012387 1.       ]\n",
      "[1.7467141e-04 1.0000000e+00]\n",
      "[0.10398987 0.9999988 ]\n",
      "[0.99977183 0.9999964 ]\n",
      "[0.9999775 0.9999989]\n",
      "[0.001398   0.99998736]\n",
      "[6.5863132e-06 1.0000000e+00]\n",
      "[0.9999994 1.       ]\n",
      "[0.00150341 0.99999845]\n",
      "[1.218915e-05 9.999999e-01]\n",
      "[0.9999976 0.9999998]\n",
      "[0.9988513 0.9999933]\n",
      "[0.9999983  0.99999994]\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "predict = model.predict(x_test/255.0)\n",
    "print(time.time()-t)\n",
    "for i in range(x_test.shape[0]):\n",
    "    img = x_test[i]\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    print(predict[i])\n",
    "    if predict[i,1]>0.5:\n",
    "        if predict[i,0]<0.9:\n",
    "            cv2.rectangle(img, (0,0), (30, 30), (0, 0, 255), -1)\n",
    "        else:\n",
    "            cv2.rectangle(img, (98, 0), (128, 30), (0, 0, 255), -1)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    k =cv2.waitKey(0)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    img = cv2.imread('test/cropleft1.png')\n",
    "\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "#     print img.shape\n",
    "#     with graph.as_default():\n",
    "#         set_session(sess)\n",
    "#         side, conf = model.predict(img)\n",
    "    side, conf = model.predict(np.array([img])/255.0)[0]\n",
    "    \n",
    "\n",
    "    print side, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.090714e-06 1.0\n"
     ]
    }
   ],
   "source": [
    "classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import timedelta\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# graph = tf.get_default_graph()\n",
    "\n",
    "# set_session(sess)\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "\n",
    "sign_cascade = cv2.CascadeClassifier('models/cascade2.xml')\n",
    "\n",
    "crop = np.zeros((64, 64), np.uint8)\n",
    "\n",
    "def FindSign(img):\n",
    "    signs = sign_cascade.detectMultiScale(img,\n",
    "                                          scaleFactor=1.03,\n",
    "                                          minNeighbors=2,\n",
    "                                          minSize=(19, 19),\n",
    "                                          maxSize=(60, 60),\n",
    "                                          flags=0)\n",
    "    return signs\n",
    "\n",
    "\n",
    "def Cascade_sign(img_):\n",
    "    global crop, sess, graph\n",
    "    t = 2\n",
    "    side = None\n",
    "    img = img_[0:100, ...].copy()\n",
    "    img2 = img_[0:100, ...].copy()\n",
    "    signs = FindSign(img2)\n",
    "    position = None\n",
    "    for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)\n",
    "            position = [x, y, w, h]\n",
    "            crop = img[y - t:y + h + t, x - t:x + w + t, :]\n",
    "            crop = cv2.resize(crop, (64, 64))\n",
    "            start = timeit.default_timer()\n",
    "#             with graph.as_default():\n",
    "#                 set_session(sess)\n",
    "#                 _side, confident = my_model.predict(np.array([crop]) /\n",
    "#                                                     255.0)[0]\n",
    "#                 print('toi dang o day')\n",
    "#                 print('confident = ', confident)\n",
    "            _side, confident = model.predict(np.array([crop]) /\n",
    "                                                    255.0)[0]\n",
    "            stop = timeit.default_timer()\n",
    "            print ('Thoi gian chay model la ', stop - start)\n",
    "            #_side, confident = sign_model.predict(np.array([crop])/255.0)[0]\n",
    "            # _side = 0\n",
    "            # confident = 0.9\n",
    "            if _side < 0.5:\n",
    "                _side = 0\n",
    "            else:\n",
    "                _side = 1\n",
    "            if confident > 0.5:\n",
    "                side = _side\n",
    "            # cv2.rectangle(img,(x-t,y-t),(x+w+t,y+h+t),(0,255,0),2)\n",
    "            # font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # cv2.putText(img,str(confident),(x-10,y-10), font, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            # #cv2.imshow('crop', crop)\n",
    "    return crop, side, img, position\n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "def testImage():\n",
    "    img = cv2.imread('test/left1.png')\n",
    "\n",
    "    crop1, side, img2, pos = Cascade_sign(img)\n",
    "    #cv2.imshow('crop', crop)\n",
    "    #cv2.imshow('sign', img2)\n",
    "    #cv2.imshow('image', img)\n",
    "    print ('side= ', side)\n",
    "    print ('pos= ', pos)\n",
    "    #getMask(img)\n",
    "\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test/left1.png')\n",
    "\n",
    "signs = FindSign(img)\n",
    "\n",
    "for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
