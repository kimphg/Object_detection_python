{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:06.163853Z",
     "start_time": "2019-04-01T13:53:59.624780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 243 61\n",
      "(304, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "x = np.load(\"x.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "shuffe_index = np.random.permutation(x.shape[0])\n",
    "N = x.shape[0]\n",
    "K = int(0.8*N)#number of train samples\n",
    "index = np.random.permutation(N)\n",
    "x_train = x[index[0:K]]\n",
    "y_train = y[index[0:K]]\n",
    "x_test = x[index[K:]]\n",
    "y_test = y[index[K:]]\n",
    "print(N, K, N - K)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 85 118 114]\n",
      "   [ 84 119 115]\n",
      "   [ 89 125 125]\n",
      "   ...\n",
      "   [ 43  63  58]\n",
      "   [ 45  62  58]\n",
      "   [ 45  62  58]]\n",
      "\n",
      "  [[ 83 116 112]\n",
      "   [ 83 118 114]\n",
      "   [ 86 125 123]\n",
      "   ...\n",
      "   [ 43  63  58]\n",
      "   [ 46  63  59]\n",
      "   [ 46  63  59]]\n",
      "\n",
      "  [[ 82 118 112]\n",
      "   [ 81 118 114]\n",
      "   [ 81 121 119]\n",
      "   ...\n",
      "   [ 43  63  58]\n",
      "   [ 45  62  58]\n",
      "   [ 44  61  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98 140 145]\n",
      "   [ 97 139 144]\n",
      "   [ 95 138 141]\n",
      "   ...\n",
      "   [126 156 157]\n",
      "   [107 134 138]\n",
      "   [101 128 132]]\n",
      "\n",
      "  [[ 81 121 126]\n",
      "   [ 80 120 125]\n",
      "   [ 77 117 122]\n",
      "   ...\n",
      "   [140 169 173]\n",
      "   [133 160 164]\n",
      "   [130 157 161]]\n",
      "\n",
      "  [[ 77 117 122]\n",
      "   [ 76 116 121]\n",
      "   [ 73 113 118]\n",
      "   ...\n",
      "   [140 171 174]\n",
      "   [137 164 168]\n",
      "   [132 159 163]]]\n",
      "\n",
      "\n",
      " [[[ 56  93  85]\n",
      "   [ 56  93  85]\n",
      "   [ 65  99  92]\n",
      "   ...\n",
      "   [ 39  60  57]\n",
      "   [ 38  57  54]\n",
      "   [ 38  57  54]]\n",
      "\n",
      "  [[ 54  91  83]\n",
      "   [ 55  92  84]\n",
      "   [ 63  97  90]\n",
      "   ...\n",
      "   [ 39  60  57]\n",
      "   [ 38  57  54]\n",
      "   [ 38  57  54]]\n",
      "\n",
      "  [[ 47  83  77]\n",
      "   [ 48  84  78]\n",
      "   [ 56  92  86]\n",
      "   ...\n",
      "   [ 41  61  56]\n",
      "   [ 42  59  55]\n",
      "   [ 44  61  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 37 116 102]\n",
      "   [ 38 117 103]\n",
      "   [ 37 116 102]\n",
      "   ...\n",
      "   [ 52 105  96]\n",
      "   [ 49 102  93]\n",
      "   [ 48 101  92]]\n",
      "\n",
      "  [[ 44 121 107]\n",
      "   [ 43 120 106]\n",
      "   [ 40 115 101]\n",
      "   ...\n",
      "   [ 58 102  95]\n",
      "   [ 55  99  92]\n",
      "   [ 53 100  92]]\n",
      "\n",
      "  [[ 47 122 108]\n",
      "   [ 46 121 107]\n",
      "   [ 43 115 102]\n",
      "   ...\n",
      "   [ 60 101  94]\n",
      "   [ 57  99  92]\n",
      "   [ 57  99  92]]]\n",
      "\n",
      "\n",
      " [[[ 69 112 109]\n",
      "   [ 71 114 111]\n",
      "   [ 69 113 107]\n",
      "   ...\n",
      "   [ 81 132 134]\n",
      "   [ 79 135 136]\n",
      "   [ 79 136 137]]\n",
      "\n",
      "  [[ 71 111 109]\n",
      "   [ 71 111 109]\n",
      "   [ 70 111 106]\n",
      "   ...\n",
      "   [ 84 132 134]\n",
      "   [ 81 132 134]\n",
      "   [ 80 134 135]]\n",
      "\n",
      "  [[ 76 113 109]\n",
      "   [ 76 113 109]\n",
      "   [ 79 114 110]\n",
      "   ...\n",
      "   [ 87 128 130]\n",
      "   [ 82 127 130]\n",
      "   [ 79 127 129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 56 113 105]\n",
      "   [ 56 113 105]\n",
      "   [ 65 116 109]\n",
      "   ...\n",
      "   [ 52  89  81]\n",
      "   [ 50  87  79]\n",
      "   [ 47  86  78]]\n",
      "\n",
      "  [[ 78 132 127]\n",
      "   [ 78 132 125]\n",
      "   [ 84 132 126]\n",
      "   ...\n",
      "   [ 42  92  82]\n",
      "   [ 37  87  77]\n",
      "   [ 35  85  75]]\n",
      "\n",
      "  [[ 83 137 132]\n",
      "   [ 85 136 132]\n",
      "   [ 89 137 131]\n",
      "   ...\n",
      "   [ 40  93  83]\n",
      "   [ 33  89  78]\n",
      "   [ 33  89  78]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 81 120 104]\n",
      "   [ 83 122 106]\n",
      "   [ 86 127 112]\n",
      "   ...\n",
      "   [ 82 136 131]\n",
      "   [ 92 148 143]\n",
      "   [ 97 153 148]]\n",
      "\n",
      "  [[ 77 116 100]\n",
      "   [ 78 120 103]\n",
      "   [ 83 124 109]\n",
      "   ...\n",
      "   [ 82 136 131]\n",
      "   [ 91 145 140]\n",
      "   [ 94 148 143]]\n",
      "\n",
      "  [[ 63 105  88]\n",
      "   [ 67 109  92]\n",
      "   [ 75 116 101]\n",
      "   ...\n",
      "   [ 84 134 130]\n",
      "   [ 85 135 131]\n",
      "   [ 83 134 130]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[133 164 165]\n",
      "   [131 162 163]\n",
      "   [129 160 163]\n",
      "   ...\n",
      "   [ 30 110  93]\n",
      "   [ 37 117 100]\n",
      "   [ 38 118 101]]\n",
      "\n",
      "  [[137 167 168]\n",
      "   [134 164 165]\n",
      "   [130 159 163]\n",
      "   ...\n",
      "   [ 33 115  97]\n",
      "   [ 33 115  97]\n",
      "   [ 34 116  98]]\n",
      "\n",
      "  [[139 169 170]\n",
      "   [136 166 167]\n",
      "   [133 160 164]\n",
      "   ...\n",
      "   [ 31 115  97]\n",
      "   [ 30 114  96]\n",
      "   [ 33 117  99]]]\n",
      "\n",
      "\n",
      " [[[142 148 137]\n",
      "   [148 154 143]\n",
      "   [ 95 103  92]\n",
      "   ...\n",
      "   [ 49  81  76]\n",
      "   [ 54  81  77]\n",
      "   [ 52  80  74]]\n",
      "\n",
      "  [[140 148 137]\n",
      "   [142 150 139]\n",
      "   [103 111 100]\n",
      "   ...\n",
      "   [ 60  92  87]\n",
      "   [ 53  84  77]\n",
      "   [ 72 100  94]]\n",
      "\n",
      "  [[135 145 132]\n",
      "   [142 152 139]\n",
      "   [101 110  97]\n",
      "   ...\n",
      "   [ 61  93  88]\n",
      "   [ 50  81  74]\n",
      "   [ 72 103  94]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[132 159 169]\n",
      "   [133 160 170]\n",
      "   [130 159 168]\n",
      "   ...\n",
      "   [ 38 129 104]\n",
      "   [ 29 120  94]\n",
      "   [ 35 126 100]]\n",
      "\n",
      "  [[133 160 170]\n",
      "   [133 160 170]\n",
      "   [131 159 170]\n",
      "   ...\n",
      "   [ 41 132 107]\n",
      "   [ 42 129 103]\n",
      "   [ 33 120  92]]\n",
      "\n",
      "  [[128 155 165]\n",
      "   [123 152 161]\n",
      "   [126 154 165]\n",
      "   ...\n",
      "   [ 49 138 112]\n",
      "   [ 46 133 107]\n",
      "   [ 31 116  88]]]\n",
      "\n",
      "\n",
      " [[[ 69 124 127]\n",
      "   [ 74 125 128]\n",
      "   [ 76 119 122]\n",
      "   ...\n",
      "   [ 74  78  73]\n",
      "   [ 75  79  74]\n",
      "   [ 75  79  74]]\n",
      "\n",
      "  [[ 71 124 127]\n",
      "   [ 74 123 125]\n",
      "   [ 77 118 121]\n",
      "   ...\n",
      "   [ 73  77  72]\n",
      "   [ 75  79  74]\n",
      "   [ 74  78  73]]\n",
      "\n",
      "  [[ 74 123 125]\n",
      "   [ 75 121 122]\n",
      "   [ 81 119 121]\n",
      "   ...\n",
      "   [ 74  78  73]\n",
      "   [ 75  79  74]\n",
      "   [ 75  79  74]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[105 129 127]\n",
      "   [101 128 124]\n",
      "   [ 89 121 116]\n",
      "   ...\n",
      "   [ 97 153 142]\n",
      "   [ 92 145 136]\n",
      "   [ 91 142 134]]\n",
      "\n",
      "  [[114 141 137]\n",
      "   [107 139 134]\n",
      "   [ 91 127 121]\n",
      "   ...\n",
      "   [100 160 149]\n",
      "   [ 92 149 140]\n",
      "   [ 91 146 137]]\n",
      "\n",
      "  [[115 145 140]\n",
      "   [111 143 138]\n",
      "   [ 91 130 122]\n",
      "   ...\n",
      "   [ 98 160 148]\n",
      "   [ 88 148 138]\n",
      "   [ 87 144 135]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:08.270193Z",
     "start_time": "2019-04-01T13:54:08.168465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         608       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 7,442\n",
      "Trainable params: 7,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(5, 5), strides= (2, 2), padding='same',input_shape=( 64, 64, 3,)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 243\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape[0], x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:20.042987Z",
     "start_time": "2019-04-01T13:54:09.103294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "8/7 [===============================] - 0s 48ms/step - loss: 0.4926 - val_loss: 0.3511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35113, saving model to models/sign.h5\n",
      "Epoch 2/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.3268 - val_loss: 0.2611\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35113 to 0.26112, saving model to models/sign.h5\n",
      "Epoch 3/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.2668 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26112 to 0.24335, saving model to models/sign.h5\n",
      "Epoch 4/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.2669 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24335 to 0.16945, saving model to models/sign.h5\n",
      "Epoch 5/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 0.2338 - val_loss: 0.1265\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16945 to 0.12653, saving model to models/sign.h5\n",
      "Epoch 6/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.1509 - val_loss: 0.0832\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12653 to 0.08322, saving model to models/sign.h5\n",
      "Epoch 7/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.1188 - val_loss: 0.0525\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08322 to 0.05248, saving model to models/sign.h5\n",
      "Epoch 8/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 0.0779 - val_loss: 0.0421\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05248 to 0.04208, saving model to models/sign.h5\n",
      "Epoch 9/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0675 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04208 to 0.02256, saving model to models/sign.h5\n",
      "Epoch 10/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0444 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02256\n",
      "Epoch 11/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0287 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02256 to 0.01331, saving model to models/sign.h5\n",
      "Epoch 12/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01331\n",
      "Epoch 13/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01331 to 0.01063, saving model to models/sign.h5\n",
      "Epoch 14/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01063\n",
      "Epoch 15/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01063\n",
      "Epoch 16/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.0178\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01063\n",
      "Epoch 17/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01063\n",
      "Epoch 18/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01063\n",
      "Epoch 19/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01063\n",
      "Epoch 20/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0042 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01063\n",
      "Epoch 21/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01063\n",
      "Epoch 22/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01063 to 0.00612, saving model to models/sign.h5\n",
      "Epoch 23/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00612\n",
      "Epoch 24/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00612\n",
      "Epoch 25/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00612\n",
      "Epoch 26/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00612\n",
      "Epoch 27/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00612\n",
      "Epoch 28/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00612 to 0.00556, saving model to models/sign.h5\n",
      "Epoch 29/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00556\n",
      "Epoch 30/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00556\n",
      "Epoch 31/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00556\n",
      "Epoch 32/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00556\n",
      "Epoch 33/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00556\n",
      "Epoch 34/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 7.0885e-04 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00556\n",
      "Epoch 35/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00556 to 0.00313, saving model to models/sign.h5\n",
      "Epoch 36/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00313 to 0.00272, saving model to models/sign.h5\n",
      "Epoch 37/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00272\n",
      "Epoch 38/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00272\n",
      "Epoch 39/50\n",
      "8/7 [===============================] - 0s 11ms/step - loss: 9.6808e-04 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00272\n",
      "Epoch 40/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00272\n",
      "Epoch 41/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00272\n",
      "Epoch 42/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00272\n",
      "Epoch 43/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00272\n",
      "Epoch 44/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00272\n",
      "Epoch 45/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 8.4928e-04\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00272 to 0.00085, saving model to models/sign.h5\n",
      "Epoch 46/50\n",
      "8/7 [===============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00085\n",
      "Epoch 47/50\n",
      "8/7 [===============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00085\n",
      "Epoch 48/50\n",
      "8/7 [===============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00085\n",
      "Epoch 49/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 8.8011e-04 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00085\n",
      "Epoch 50/50\n",
      "8/7 [===============================] - 0s 12ms/step - loss: 6.5204e-04 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00085\n"
     ]
    }
   ],
   "source": [
    "def generator(x, y, batch_size):\n",
    "    samples = x.shape[0]\n",
    "    steps = samples/batch_size\n",
    "    counter =0\n",
    "    while True:\n",
    "        batch_x = np.array(x[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        batch_x = batch_x/255.0\n",
    "        batch_y = np.array(y[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        counter+=1\n",
    "        yield batch_x, batch_y\n",
    "        if counter >= steps:\n",
    "            counter = 0\n",
    "# batch_size = 128\n",
    "batch_size = 32\n",
    "epochs=50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"models/sign.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history= model.fit_generator(generator(x_train, y_train, batch_size), epochs=epochs, steps_per_epoch = x_train.shape[0]/batch_size, \n",
    "                             validation_data=generator(x_test, y_test, batch_size), validation_steps = x_test.shape[0]/batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:32.252242Z",
     "start_time": "2019-04-01T13:54:31.576388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python 3.7\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import time\n",
    "model = load_model(\"models/sign.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:55:27.425674Z",
     "start_time": "2019-04-01T13:54:33.687435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.329359292984009\n",
      "[0.99999905 0.9999997 ]\n",
      "[0.999925 1.      ]\n",
      "[0.9999994 1.       ]\n",
      "[0.00102904 1.        ]\n",
      "[0.99999917 0.9999999 ]\n",
      "[0.99778086 0.9998503 ]\n",
      "[1.3351440e-05 9.9999976e-01]\n",
      "[1.2129545e-05 9.9999994e-01]\n",
      "[8.374453e-06 9.999996e-01]\n",
      "[5.6919456e-04 1.0000000e+00]\n",
      "[0.99999946 1.        ]\n",
      "[0.99999976 1.        ]\n",
      "[0.00371718 0.99999917]\n",
      "[4.4497848e-04 9.9999368e-01]\n",
      "[0.99999577 1.        ]\n",
      "[1.14142895e-05 9.99999762e-01]\n",
      "[0.9999995  0.99999994]\n",
      "[2.233684e-04 1.000000e+00]\n",
      "[0.9999914 1.       ]\n",
      "[9.834766e-06 9.999999e-01]\n",
      "[1.4662743e-05 9.9999988e-01]\n",
      "[1.385808e-05 9.999998e-01]\n",
      "[0.99998176 0.99999356]\n",
      "[3.9523840e-04 9.9999887e-01]\n",
      "[0.9999776 0.9999989]\n",
      "[2.3198128e-04 9.9999988e-01]\n",
      "[0.99996716 0.9999995 ]\n",
      "[0.00242323 1.        ]\n",
      "[0.99999857 1.        ]\n",
      "[4.3100119e-04 9.9999964e-01]\n",
      "[0.99997735 0.99998635]\n",
      "[0.9999994 0.9999995]\n",
      "[7.480383e-06 9.999997e-01]\n",
      "[0.99999964 0.9999999 ]\n",
      "[0.00110182 0.99999917]\n",
      "[1.4644861e-04 1.0000000e+00]\n",
      "[7.605553e-05 9.999994e-01]\n",
      "[0.999716   0.99999964]\n",
      "[2.309680e-05 9.999999e-01]\n",
      "[4.3413043e-04 1.0000000e+00]\n",
      "[1.8805265e-05 9.9999994e-01]\n",
      "[1.4692545e-04 9.9999988e-01]\n",
      "[0.999959   0.99999666]\n",
      "[0.9999992  0.99999994]\n",
      "[0.9999969 1.       ]\n",
      "[8.633733e-05 1.000000e+00]\n",
      "[0.99997663 0.9999998 ]\n",
      "[0.9591427 1.       ]\n",
      "[0.99999505 1.        ]\n",
      "[2.861023e-05 1.000000e+00]\n",
      "[4.1884184e-04 1.0000000e+00]\n",
      "[9.351969e-05 9.999999e-01]\n",
      "[0.99999815 0.99999994]\n",
      "[0.00100875 1.        ]\n",
      "[0.9999953 1.       ]\n",
      "[1.53929e-04 1.00000e+00]\n",
      "[2.8282404e-05 1.0000000e+00]\n",
      "[0.9999989 0.9999995]\n",
      "[0.99999845 0.99999994]\n",
      "[1.2603402e-04 9.9999946e-01]\n",
      "[0.00293016 0.99999976]\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "predict = model.predict(x_test/255.0)\n",
    "print(time.time()-t)\n",
    "for i in range(x_test.shape[0]):\n",
    "    img = x_test[i]\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    print(predict[i])\n",
    "    if predict[i,1]>0.5:\n",
    "        if predict[i,0]<0.9:\n",
    "            cv2.rectangle(img, (0,0), (30, 30), (0, 0, 255), -1)\n",
    "        else:\n",
    "            cv2.rectangle(img, (98, 0), (128, 30), (0, 0, 255), -1)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    k =cv2.waitKey(0)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    img = cv2.imread('test/cropleft1.png')\n",
    "\n",
    "    img = cv2.resize(img, (64, 64))       \n",
    "#     print img.shape\n",
    "#     with graph.as_default():\n",
    "#         set_session(sess)\n",
    "#         side, conf = model.predict(img)\n",
    "    side, conf = model.predict(np.array([img])/255.0)[0]\n",
    "    \n",
    "\n",
    "    print side, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.090714e-06 1.0\n"
     ]
    }
   ],
   "source": [
    "classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import timedelta\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# graph = tf.get_default_graph()\n",
    "\n",
    "# set_session(sess)\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "\n",
    "sign_cascade = cv2.CascadeClassifier('models/cascade2.xml')\n",
    "\n",
    "crop = np.zeros((64, 64), np.uint8)\n",
    "\n",
    "def FindSign(img):\n",
    "    signs = sign_cascade.detectMultiScale(img,\n",
    "                                          scaleFactor=1.03,\n",
    "                                          minNeighbors=2,\n",
    "                                          minSize=(19, 19),\n",
    "                                          maxSize=(60, 60),\n",
    "                                          flags=0)\n",
    "    return signs\n",
    "\n",
    "\n",
    "def Cascade_sign(img_):\n",
    "    global crop, sess, graph\n",
    "    t = 2\n",
    "    side = None\n",
    "    img = img_[0:100, ...].copy()\n",
    "    img2 = img_[0:100, ...].copy()\n",
    "    signs = FindSign(img2)\n",
    "    position = None\n",
    "    for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)\n",
    "            position = [x, y, w, h]\n",
    "            crop = img[y - t:y + h + t, x - t:x + w + t, :]\n",
    "            crop = cv2.resize(crop, (64, 64))\n",
    "            start = timeit.default_timer()\n",
    "#             with graph.as_default():\n",
    "#                 set_session(sess)\n",
    "#                 _side, confident = my_model.predict(np.array([crop]) /\n",
    "#                                                     255.0)[0]\n",
    "#                 print('toi dang o day')\n",
    "#                 print('confident = ', confident)\n",
    "            _side, confident = model.predict(np.array([crop]) /\n",
    "                                                    255.0)[0]\n",
    "            stop = timeit.default_timer()\n",
    "            print ('Thoi gian chay model la ', stop - start)\n",
    "            #_side, confident = sign_model.predict(np.array([crop])/255.0)[0]\n",
    "            # _side = 0\n",
    "            # confident = 0.9\n",
    "            if _side < 0.5:\n",
    "                _side = 0\n",
    "            else:\n",
    "                _side = 1\n",
    "            if confident > 0.5:\n",
    "                side = _side\n",
    "            # cv2.rectangle(img,(x-t,y-t),(x+w+t,y+h+t),(0,255,0),2)\n",
    "            # font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # cv2.putText(img,str(confident),(x-10,y-10), font, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            # #cv2.imshow('crop', crop)\n",
    "    return crop, side, img, position\n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "def testImage():\n",
    "    img = cv2.imread('test/left1.png')\n",
    "\n",
    "    crop1, side, img2, pos = Cascade_sign(img)\n",
    "    #cv2.imshow('crop', crop)\n",
    "    #cv2.imshow('sign', img2)\n",
    "    #cv2.imshow('image', img)\n",
    "    print ('side= ', side)\n",
    "    print ('pos= ', pos)\n",
    "    #getMask(img)\n",
    "\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test/left1.png')\n",
    "\n",
    "signs = FindSign(img)\n",
    "\n",
    "for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
