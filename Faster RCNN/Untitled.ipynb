{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-308586b78cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_init_paths\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnms_wrapper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Tensorflow Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Xinlei Chen, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Demo script showing detections in sample images.\n",
    "\n",
    "See README.md for installation instructions before running.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "from model.config import cfg\n",
    "from model.test import im_detect\n",
    "from model.nms_wrapper import nms\n",
    "\n",
    "from utils.timer import Timer\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "import argparse\n",
    "\n",
    "from nets.vgg16 import vgg16\n",
    "from nets.resnet_v1 import resnetv1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('__background__',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "           'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "\n",
    "NETS = {'vgg16': ('vgg16_faster_rcnn_iter_70000.ckpt',),'res101': ('res101_faster_rcnn_iter_110000.ckpt',)}\n",
    "DATASETS= {'pascal_voc': ('voc_2007_trainval',),'pascal_voc_0712': ('voc_2007_trainval+voc_2012_trainval',)}\n",
    "\n",
    "def vis_detections(im, class_name, dets, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    if len(inds) == 0:\n",
    "        return\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "\n",
    "def demo(sess, net, image_name):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "    im = cv2.imread(im_file)\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(sess, net, im)\n",
    "    timer.toc()\n",
    "    print('Detection took {:.3f}s for {:d} object proposals'.format(timer.total_time, boxes.shape[0]))\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    CONF_THRESH = 0.8\n",
    "    NMS_THRESH = 0.3\n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(dets, NMS_THRESH)\n",
    "        dets = dets[keep, :]\n",
    "        vis_detections(im, cls, dets, thresh=CONF_THRESH)\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Tensorflow Faster R-CNN demo')\n",
    "    parser.add_argument('--net', dest='demo_net', help='Network to use [vgg16 res101]',\n",
    "                        choices=NETS.keys(), default='res101')\n",
    "    parser.add_argument('--dataset', dest='dataset', help='Trained dataset [pascal_voc pascal_voc_0712]',\n",
    "                        choices=DATASETS.keys(), default='pascal_voc_0712')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "    args = parse_args()\n",
    "\n",
    "    # model path\n",
    "    demonet = args.demo_net\n",
    "    dataset = args.dataset\n",
    "    tfmodel = os.path.join('output', demonet, DATASETS[dataset][0], 'default',\n",
    "                              NETS[demonet][0])\n",
    "\n",
    "\n",
    "    if not os.path.isfile(tfmodel + '.meta'):\n",
    "        raise IOError(('{:s} not found.\\nDid you download the proper networks from '\n",
    "                       'our server and place them properly?').format(tfmodel + '.meta'))\n",
    "\n",
    "    # set config\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tfconfig.gpu_options.allow_growth=True\n",
    "\n",
    "    # init session\n",
    "    sess = tf.Session(config=tfconfig)\n",
    "    # load network\n",
    "    if demonet == 'vgg16':\n",
    "        net = vgg16()\n",
    "    elif demonet == 'res101':\n",
    "        net = resnetv1(num_layers=101)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    net.create_architecture(\"TEST\", 21,\n",
    "                          tag='default', anchor_scales=[8, 16, 32])\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tfmodel)\n",
    "\n",
    "    print('Loaded network {:s}'.format(tfmodel))\n",
    "\n",
    "    im_names = ['000456.jpg', '000542.jpg', '001150.jpg',\n",
    "                '001763.jpg', '004545.jpg']\n",
    "    for im_name in im_names:\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        print('Demo for data/demo/{}'.format(im_name))\n",
    "        demo(sess, net, im_name)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
