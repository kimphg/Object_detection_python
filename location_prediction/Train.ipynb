{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:06.163853Z",
     "start_time": "2019-04-01T13:53:59.624780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 243 61\n",
      "(304, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "x = np.load(\"x.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "shuffe_index = np.random.permutation(x.shape[0])\n",
    "N = x.shape[0]\n",
    "K = int(0.8*N)#number of train samples\n",
    "index = np.random.permutation(N)\n",
    "x_train = x[index[0:K]]\n",
    "y_train = y[index[0:K]]\n",
    "x_test = x[index[K:]]\n",
    "y_test = y[index[K:]]\n",
    "print(N, K, N - K)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 30  54  52]\n",
      "   [ 29  53  51]\n",
      "   [ 27  54  51]\n",
      "   ...\n",
      "   [ 17  48  45]\n",
      "   [ 18  49  46]\n",
      "   [ 20  51  48]]\n",
      "\n",
      "  [[ 28  52  50]\n",
      "   [ 23  47  45]\n",
      "   [ 19  46  43]\n",
      "   ...\n",
      "   [ 13  44  41]\n",
      "   [ 17  48  45]\n",
      "   [ 20  51  48]]\n",
      "\n",
      "  [[ 32  56  54]\n",
      "   [ 22  46  44]\n",
      "   [ 14  38  36]\n",
      "   ...\n",
      "   [ 12  41  38]\n",
      "   [ 17  46  43]\n",
      "   [ 20  49  46]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99 128 125]\n",
      "   [ 98 127 124]\n",
      "   [104 131 128]\n",
      "   ...\n",
      "   [ 99 131 126]\n",
      "   [ 98 131 124]\n",
      "   [ 97 130 123]]\n",
      "\n",
      "  [[ 98 130 125]\n",
      "   [ 98 128 123]\n",
      "   [102 129 126]\n",
      "   ...\n",
      "   [ 97 129 124]\n",
      "   [ 95 127 122]\n",
      "   [ 92 126 120]]\n",
      "\n",
      "  [[ 96 128 123]\n",
      "   [ 96 128 123]\n",
      "   [ 99 126 123]\n",
      "   ...\n",
      "   [ 94 126 121]\n",
      "   [ 90 124 118]\n",
      "   [ 88 122 116]]]\n",
      "\n",
      "\n",
      " [[[ 56  96  95]\n",
      "   [ 58  94  94]\n",
      "   [ 65  90  92]\n",
      "   ...\n",
      "   [ 88 142 135]\n",
      "   [ 89 142 133]\n",
      "   [ 90 141 133]]\n",
      "\n",
      "  [[ 56  96  95]\n",
      "   [ 57  93  93]\n",
      "   [ 64  89  91]\n",
      "   ...\n",
      "   [ 89 141 134]\n",
      "   [ 89 140 132]\n",
      "   [ 90 141 133]]\n",
      "\n",
      "  [[ 53  95  94]\n",
      "   [ 54  92  92]\n",
      "   [ 62  90  91]\n",
      "   ...\n",
      "   [ 82 133 125]\n",
      "   [ 83 132 124]\n",
      "   [ 84 133 125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 33  77  64]\n",
      "   [ 32  78  65]\n",
      "   [ 30  76  63]\n",
      "   ...\n",
      "   [ 66  73  70]\n",
      "   [ 64  73  70]\n",
      "   [ 63  72  69]]\n",
      "\n",
      "  [[ 40  83  70]\n",
      "   [ 38  82  69]\n",
      "   [ 34  78  65]\n",
      "   ...\n",
      "   [ 62  71  68]\n",
      "   [ 61  70  67]\n",
      "   [ 60  69  66]]\n",
      "\n",
      "  [[ 42  85  72]\n",
      "   [ 41  84  71]\n",
      "   [ 36  80  67]\n",
      "   ...\n",
      "   [ 61  70  67]\n",
      "   [ 60  69  66]\n",
      "   [ 59  68  65]]]\n",
      "\n",
      "\n",
      " [[[ 31  54  50]\n",
      "   [ 32  55  51]\n",
      "   [ 29  52  48]\n",
      "   ...\n",
      "   [ 33  66  62]\n",
      "   [ 35  70  66]\n",
      "   [ 38  73  69]]\n",
      "\n",
      "  [[ 30  53  49]\n",
      "   [ 30  53  49]\n",
      "   [ 30  53  49]\n",
      "   ...\n",
      "   [ 30  65  61]\n",
      "   [ 34  69  65]\n",
      "   [ 37  72  68]]\n",
      "\n",
      "  [[ 34  55  52]\n",
      "   [ 31  52  49]\n",
      "   [ 30  51  48]\n",
      "   ...\n",
      "   [ 30  66  60]\n",
      "   [ 32  68  62]\n",
      "   [ 33  71  65]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 96 132 126]\n",
      "   [ 96 132 126]\n",
      "   [ 98 130 125]\n",
      "   ...\n",
      "   [ 97 122 118]\n",
      "   [ 96 121 117]\n",
      "   [ 94 121 117]]\n",
      "\n",
      "  [[ 97 130 126]\n",
      "   [ 96 127 124]\n",
      "   [ 97 127 122]\n",
      "   ...\n",
      "   [101 128 124]\n",
      "   [101 128 124]\n",
      "   [ 99 129 124]]\n",
      "\n",
      "  [[ 98 129 126]\n",
      "   [ 95 126 123]\n",
      "   [ 97 124 120]\n",
      "   ...\n",
      "   [101 131 126]\n",
      "   [102 132 127]\n",
      "   [102 132 127]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 90 134 127]\n",
      "   [ 84 128 121]\n",
      "   [ 74 121 113]\n",
      "   ...\n",
      "   [127 139 133]\n",
      "   [132 144 138]\n",
      "   [132 144 138]]\n",
      "\n",
      "  [[ 91 135 128]\n",
      "   [ 89 133 126]\n",
      "   [ 83 130 122]\n",
      "   ...\n",
      "   [103 115 109]\n",
      "   [113 125 119]\n",
      "   [118 130 124]]\n",
      "\n",
      "  [[ 86 130 124]\n",
      "   [ 88 132 126]\n",
      "   [ 87 133 127]\n",
      "   ...\n",
      "   [ 85  94  91]\n",
      "   [ 96 107 104]\n",
      "   [106 117 114]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126 165 167]\n",
      "   [126 165 167]\n",
      "   [126 167 169]\n",
      "   ...\n",
      "   [117 167 167]\n",
      "   [115 165 165]\n",
      "   [112 164 164]]\n",
      "\n",
      "  [[129 161 166]\n",
      "   [128 163 167]\n",
      "   [130 165 169]\n",
      "   ...\n",
      "   [104 163 159]\n",
      "   [100 159 155]\n",
      "   [ 95 156 152]]\n",
      "\n",
      "  [[131 161 166]\n",
      "   [132 162 167]\n",
      "   [130 162 167]\n",
      "   ...\n",
      "   [ 92 156 151]\n",
      "   [ 82 146 141]\n",
      "   [ 75 141 136]]]\n",
      "\n",
      "\n",
      " [[[ 90 126 126]\n",
      "   [ 89 125 125]\n",
      "   [ 84 123 121]\n",
      "   ...\n",
      "   [103 117 111]\n",
      "   [102 118 111]\n",
      "   [102 118 111]]\n",
      "\n",
      "  [[ 86 124 124]\n",
      "   [ 85 123 123]\n",
      "   [ 82 121 119]\n",
      "   ...\n",
      "   [103 117 111]\n",
      "   [102 116 110]\n",
      "   [101 117 110]]\n",
      "\n",
      "  [[ 82 122 121]\n",
      "   [ 77 119 118]\n",
      "   [ 73 116 113]\n",
      "   ...\n",
      "   [106 118 112]\n",
      "   [105 116 113]\n",
      "   [103 117 113]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 87 150 134]\n",
      "   [ 82 145 129]\n",
      "   [ 63 122 107]\n",
      "   ...\n",
      "   [ 32  88  67]\n",
      "   [ 38  88  70]\n",
      "   [ 40  88  70]]\n",
      "\n",
      "  [[ 89 162 146]\n",
      "   [ 86 157 141]\n",
      "   [ 67 134 119]\n",
      "   ...\n",
      "   [ 33  90  69]\n",
      "   [ 33  85  67]\n",
      "   [ 34  84  66]]\n",
      "\n",
      "  [[ 91 169 152]\n",
      "   [ 85 160 144]\n",
      "   [ 63 136 120]\n",
      "   ...\n",
      "   [ 31  90  69]\n",
      "   [ 27  82  63]\n",
      "   [ 29  81  63]]]\n",
      "\n",
      "\n",
      " [[[ 74 112 106]\n",
      "   [ 75 113 107]\n",
      "   [ 68 106 100]\n",
      "   ...\n",
      "   [ 88 132 133]\n",
      "   [104 148 149]\n",
      "   [106 150 151]]\n",
      "\n",
      "  [[ 75 113 107]\n",
      "   [ 75 113 107]\n",
      "   [ 69 107 101]\n",
      "   ...\n",
      "   [ 84 130 131]\n",
      "   [ 97 143 144]\n",
      "   [100 146 147]]\n",
      "\n",
      "  [[ 74 115 108]\n",
      "   [ 75 116 109]\n",
      "   [ 75 116 109]\n",
      "   ...\n",
      "   [ 79 127 128]\n",
      "   [ 85 133 134]\n",
      "   [ 86 134 135]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 97 149 142]\n",
      "   [ 95 149 142]\n",
      "   [ 84 138 131]\n",
      "   ...\n",
      "   [ 41  95  82]\n",
      "   [ 40  93  80]\n",
      "   [ 40  90  78]]\n",
      "\n",
      "  [[115 160 157]\n",
      "   [115 160 157]\n",
      "   [109 154 151]\n",
      "   ...\n",
      "   [ 38  97  83]\n",
      "   [ 39  95  82]\n",
      "   [ 38  94  81]]\n",
      "\n",
      "  [[124 164 162]\n",
      "   [123 163 161]\n",
      "   [117 160 157]\n",
      "   ...\n",
      "   [ 36  98  84]\n",
      "   [ 37  96  82]\n",
      "   [ 34  93  79]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:08.270193Z",
     "start_time": "2019-04-01T13:54:08.168465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 8)         608       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 7,442\n",
      "Trainable params: 7,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(5, 5), strides= (2, 2), padding='same',input_shape=( 64, 64, 3,)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides= (1, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 243)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape[0], x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:20.042987Z",
     "start_time": "2019-04-01T13:54:09.103294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 0.6455 - val_loss: 0.5486\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54857, saving model to models/sign.h5\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4481 - val_loss: 0.3420\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54857 to 0.34198, saving model to models/sign.h5\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3329 - val_loss: 0.2812\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34198 to 0.28117, saving model to models/sign.h5\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2987 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28117 to 0.23243, saving model to models/sign.h5\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2490 - val_loss: 0.1904\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23243 to 0.19043, saving model to models/sign.h5\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2381 - val_loss: 0.1484\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19043 to 0.14838, saving model to models/sign.h5\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1818 - val_loss: 0.1122\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14838 to 0.11223, saving model to models/sign.h5\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1447 - val_loss: 0.0749\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11223 to 0.07493, saving model to models/sign.h5\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1316 - val_loss: 0.0514\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07493 to 0.05141, saving model to models/sign.h5\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1021 - val_loss: 0.0352\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05141 to 0.03517, saving model to models/sign.h5\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0583 - val_loss: 0.0227\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03517 to 0.02268, saving model to models/sign.h5\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0489 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02268 to 0.01613, saving model to models/sign.h5\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0373 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01613 to 0.00999, saving model to models/sign.h5\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0260 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00999 to 0.00619, saving model to models/sign.h5\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00619 to 0.00428, saving model to models/sign.h5\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00428 to 0.00392, saving model to models/sign.h5\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0023\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00392 to 0.00233, saving model to models/sign.h5\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0019\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00233 to 0.00186, saving model to models/sign.h5\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0015\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00186 to 0.00153, saving model to models/sign.h5\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00153 to 0.00131, saving model to models/sign.h5\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00131\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0010\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00131 to 0.00104, saving model to models/sign.h5\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 9.2927e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00104 to 0.00093, saving model to models/sign.h5\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 8.3221e-04\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00093 to 0.00083, saving model to models/sign.h5\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 7.5425e-04\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00083 to 0.00075, saving model to models/sign.h5\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 5.9146e-04\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00075 to 0.00059, saving model to models/sign.h5\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 4.7933e-04\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00059 to 0.00048, saving model to models/sign.h5\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 4.2532e-04\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00048 to 0.00043, saving model to models/sign.h5\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 4.4495e-04\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00043\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 3.7031e-04\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00043 to 0.00037, saving model to models/sign.h5\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 3.2690e-04\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00037 to 0.00033, saving model to models/sign.h5\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 3.5628e-04\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00033\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 2.6487e-04\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00033 to 0.00026, saving model to models/sign.h5\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 2.3047e-04\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00026 to 0.00023, saving model to models/sign.h5\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 2.0851e-04\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00023 to 0.00021, saving model to models/sign.h5\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 7.6316e-04 - val_loss: 1.8014e-04\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00021 to 0.00018, saving model to models/sign.h5\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 1.5961e-04\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00018 to 0.00016, saving model to models/sign.h5\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 1.4575e-04\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00016 to 0.00015, saving model to models/sign.h5\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 9.9170e-04 - val_loss: 1.4929e-04\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00015\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.5465e-04 - val_loss: 1.4416e-04\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00015 to 0.00014, saving model to models/sign.h5\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 1.3067e-04\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00014 to 0.00013, saving model to models/sign.h5\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.4824e-04 - val_loss: 1.2167e-04\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00013 to 0.00012, saving model to models/sign.h5\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 1.0885e-04\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00012 to 0.00011, saving model to models/sign.h5\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 1.0669e-04\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00011 to 0.00011, saving model to models/sign.h5\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 8.4336e-04 - val_loss: 1.0925e-04\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00011\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 1.1107e-04\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00011\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.3581e-04 - val_loss: 1.0041e-04\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00011 to 0.00010, saving model to models/sign.h5\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1248e-04 - val_loss: 8.7380e-05\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00010 to 0.00009, saving model to models/sign.h5\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.5727e-04 - val_loss: 7.7020e-05\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00009 to 0.00008, saving model to models/sign.h5\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.6724e-04 - val_loss: 7.1281e-05\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00008 to 0.00007, saving model to models/sign.h5\n"
     ]
    }
   ],
   "source": [
    "def generator(x, y, batch_size):\n",
    "    samples = x.shape[0]\n",
    "    steps = samples/batch_size\n",
    "    counter =0\n",
    "    while True:\n",
    "        batch_x = np.array(x[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        batch_x = batch_x/255.0\n",
    "        batch_y = np.array(y[batch_size*counter: batch_size*(counter+1)]).astype(np.float32)\n",
    "        counter+=1\n",
    "        yield batch_x, batch_y\n",
    "        if counter >= steps:\n",
    "            counter = 0\n",
    "# batch_size = 128\n",
    "batch_size = 32\n",
    "epochs=50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"models/sign.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history= model.fit_generator(generator(x_train, y_train, batch_size), epochs=epochs, steps_per_epoch = x_train.shape[0]/batch_size, \n",
    "                             validation_data=generator(x_test, y_test, batch_size), validation_steps = x_test.shape[0]/batch_size, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:54:32.252242Z",
     "start_time": "2019-04-01T13:54:31.576388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vpoat/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/vpoat/.local/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/vpoat/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import time\n",
    "model = load_model(\"models/sign.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T13:55:27.425674Z",
     "start_time": "2019-04-01T13:54:33.687435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0145812034607\n",
      "[0.99999636 1.        ]\n",
      "[0.00135627 0.99999976]\n",
      "[0.998657 1.      ]\n",
      "[0.9998561  0.99999964]\n",
      "[0.9999871 1.       ]\n",
      "[0.9998431  0.99999994]\n",
      "[0.9999994 1.       ]\n",
      "[1.2496114e-04 9.9999893e-01]\n",
      "[0.9999989 1.       ]\n",
      "[2.682209e-07 1.000000e+00]\n",
      "[8.6426735e-07 1.0000000e+00]\n",
      "[0.99999845 1.        ]\n",
      "[0.99993926 1.        ]\n",
      "[1.8805265e-05 1.0000000e+00]\n",
      "[0.99972016 1.        ]\n",
      "[0.99999905 1.        ]\n",
      "[0.99999714 1.        ]\n",
      "[3.0961633e-04 9.9999976e-01]\n",
      "[0.9999729 1.       ]\n",
      "[8.0764294e-05 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "predict = model.predict(x_test/255.0)\n",
    "print(time.time()-t)\n",
    "for i in range(x_test.shape[0]):\n",
    "    img = x_test[i]\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    print(predict[i])\n",
    "    if predict[i,1]>0.5:\n",
    "        if predict[i,0]<0.9:\n",
    "            cv2.rectangle(img, (0,0), (30, 30), (0, 0, 255), -1)\n",
    "        else:\n",
    "            cv2.rectangle(img, (98, 0), (128, 30), (0, 0, 255), -1)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    k =cv2.waitKey(0)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    img = cv2.imread('test/cropleft1.png')\n",
    "\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "#     print img.shape\n",
    "#     with graph.as_default():\n",
    "#         set_session(sess)\n",
    "#         side, conf = model.predict(img)\n",
    "    side, conf = model.predict(np.array([img])/255.0)[0]\n",
    "    \n",
    "\n",
    "    print side, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.090714e-06 1.0\n"
     ]
    }
   ],
   "source": [
    "classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import timedelta\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# graph = tf.get_default_graph()\n",
    "\n",
    "# set_session(sess)\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "# my_model = load_model('models/sign_fix.h5')\n",
    "\n",
    "sign_cascade = cv2.CascadeClassifier('models/cascade2.xml')\n",
    "\n",
    "crop = np.zeros((64, 64), np.uint8)\n",
    "\n",
    "def FindSign(img):\n",
    "    signs = sign_cascade.detectMultiScale(img,\n",
    "                                          scaleFactor=1.03,\n",
    "                                          minNeighbors=2,\n",
    "                                          minSize=(19, 19),\n",
    "                                          maxSize=(60, 60),\n",
    "                                          flags=0)\n",
    "    return signs\n",
    "\n",
    "\n",
    "def Cascade_sign(img_):\n",
    "    global crop, sess, graph\n",
    "    t = 2\n",
    "    side = None\n",
    "    img = img_[0:100, ...].copy()\n",
    "    img2 = img_[0:100, ...].copy()\n",
    "    signs = FindSign(img2)\n",
    "    position = None\n",
    "    for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)\n",
    "            position = [x, y, w, h]\n",
    "            crop = img[y - t:y + h + t, x - t:x + w + t, :]\n",
    "            crop = cv2.resize(crop, (64, 64))\n",
    "            start = timeit.default_timer()\n",
    "#             with graph.as_default():\n",
    "#                 set_session(sess)\n",
    "#                 _side, confident = my_model.predict(np.array([crop]) /\n",
    "#                                                     255.0)[0]\n",
    "#                 print('toi dang o day')\n",
    "#                 print('confident = ', confident)\n",
    "            _side, confident = model.predict(np.array([crop]) /\n",
    "                                                    255.0)[0]\n",
    "            stop = timeit.default_timer()\n",
    "            print ('Thoi gian chay model la ', stop - start)\n",
    "            #_side, confident = sign_model.predict(np.array([crop])/255.0)[0]\n",
    "            # _side = 0\n",
    "            # confident = 0.9\n",
    "            if _side < 0.5:\n",
    "                _side = 0\n",
    "            else:\n",
    "                _side = 1\n",
    "            if confident > 0.5:\n",
    "                side = _side\n",
    "            # cv2.rectangle(img,(x-t,y-t),(x+w+t,y+h+t),(0,255,0),2)\n",
    "            # font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # cv2.putText(img,str(confident),(x-10,y-10), font, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            # #cv2.imshow('crop', crop)\n",
    "    return crop, side, img, position\n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "def testImage():\n",
    "    img = cv2.imread('test/left1.png')\n",
    "\n",
    "    crop1, side, img2, pos = Cascade_sign(img)\n",
    "    #cv2.imshow('crop', crop)\n",
    "    #cv2.imshow('sign', img2)\n",
    "    #cv2.imshow('image', img)\n",
    "    print ('side= ', side)\n",
    "    print ('pos= ', pos)\n",
    "    #getMask(img)\n",
    "\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test/left1.png')\n",
    "\n",
    "signs = FindSign(img)\n",
    "\n",
    "for (x, y, w, h) in signs:\n",
    "        if x > 5 and y > 5 and x + w < 475 and y + h < 95 and 1.0 * h / w > 0.85 and 1.0 * h / w < 1.3:\n",
    "            print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
